import os
import json
import random
import argparse
import dill
from datetime import datetime
from smolagents import TransformersModel, CodeAgent, LogLevel
from custom_tools import *
import inseq
from transformers import AutoTokenizer

# ==============================================================================
# == 1. Function Definition
# ==============================================================================

def run_my_agent(task_prompt: str, tools_to_use: list) -> str:
    """
    Runs the LLM agent.
    
    Args:
        task_prompt: The input string (=task prompt) for the agent.
        
    Returns:
        The full log of the agent run as a list object.
    """

    my_tools = tools_to_use

    model = TransformersModel(model_id=model_id)
    agent = CodeAgent(
        model=model, 
        #add_base_tools=True, 
        tools=my_tools,
        verbosity_level=LogLevel.INFO , #LogLevel.DEBUG, 
        max_steps=1
        )
    agent.run(task_prompt)

    return agent.memory.get_full_steps()


def prepare_for_inseq(memory_steps, tokenizer):
    """
    Extracts and formats the system + user prompts (formatted as the model sees them during inference)
    as well as the generated output from step 1 of smolagents memory.
    Preparation for inseq attribution.

    Args:
        memory_steps: list object as created by agent.memory.get_full_steps()
        tokenizer: A Transformers AutoTokenizer object
    
    Returns:
        input_text and output_text strings to be used by inseq
    """

    step1 = memory_steps[1]  # first step with actual model I/O
    messages = step1["model_input_messages"]
    assistant_msg = step1["model_output_message"]

    # Flatten the content lists into strings
    def extract_text(msg):
        if isinstance(msg["content"], list):
            return "".join(
                part["text"] for part in msg["content"] if part["type"] == "text"
            )
        elif isinstance(msg["content"], str):
            return msg["content"]
        return ""

    system_text = extract_text(next(m for m in messages if m["role"].name == "SYSTEM"))
    user_text   = extract_text(next(m for m in messages if m["role"].name == "USER"))

    # Format input exactly like Qwen sees it
    input_text = tokenizer.apply_chat_template(
        [
            {"role": "system", "content": system_text},
            {"role": "user", "content": user_text},
        ],
        tokenize=False,
        add_generation_prompt=True,  # ensures <|assistant|> token is included
    )

    # Assistant output (already a string in smolagents memory)
    output_text = assistant_msg["content"]

    return input_text, output_text


def run_inseq_analysis(prompt: str, generated_text: str) -> object:
    """
    Runs the Inseq attribution analysis on an agent run.
    
    Args:
        prompt: The original input prompt (system prompt + task prompt).
        generated_text: The text generated by the agent.
        
    Returns:
        The complex attribution output object from Inseq.
    """
    print("  -> Running Inseq analysis...")

    inseq_model = inseq.load_model(model_id, "attention")#"saliency")#"integrated_gradients") #die choice hier auch als argsparse machen, was dieser function als variable Ã¼berreicht wird

    attribution_result = inseq_model.attribute(
        prompt,
        generated_texts=prompt + generated_text
        #skip_special_tokens=True ## was will ich hier?
    )
    
    return attribution_result


# ==============================================================================
# == 2. Execution Loop
# ==============================================================================

if __name__ == "__main__":

    # --- Select Model ID ---
    model_id_short = "Qwen3-0.6B" #"Qwen3-1.7B" # "Qwen3-4B" # "gemma-3-4b-it"  <----------------- select model size here
    model_id = "Qwen/" + model_id_short #"google/ 

    # --- Setup Tokenizer ---
    tokenizer = AutoTokenizer.from_pretrained(model_id)

    # --- Load models ---
    # On a computer with enough memory, it could be better to load the models here (once)
    # and pass them to the functions. For both smolagents and inseq models.
    # On my machine (low memory, never calculating the whole dataset) its probably best this way.

    # --- Setup Argument Parser ---
    parser = argparse.ArgumentParser(description="Run agent and Inseq analysis for a specific category of tasks.")
    parser.add_argument("--category", type=str, required=True, help="The category name from the dataset (e.g., 'entertainment and media').")
    args = parser.parse_args()
    
    selected_category = args.category
    
    # --- Setup Paths and Directories ---
    TASKS_FILE = os.path.join("data", "dataset_combined.json")
    TOOL_LIST_FILE = os.path.join("data", "tool_list_combined.json")
    OUTPUT_DIR = os.path.join("outputs", selected_category.replace(" ", "_")) #selected_category.replace kann glaub weg

    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    print(f"Starting process for category: '{selected_category}'")
    
    # --- Load and Select Tools Dynamically ---
    try:
        with open(TOOL_LIST_FILE, 'r') as f:
            all_tools_by_category = json.load(f)
    except FileNotFoundError:
        print(f"ERROR: Tool list file not found at {TOOL_LIST_FILE}")
        exit()
        
    # Get the tools for the selected category
    tools_for_category = all_tools_by_category.get(selected_category)
    if not tools_for_category:
        print(f"ERROR: Category '{selected_category}' not found in {TOOL_LIST_FILE}")
        exit()
    print(f"Found {len(tools_for_category)} tools for category '{selected_category}'.")
    
    # Get a flat list of all other tools
    other_tools = [
        tool_name
        for category, tool_list in all_tools_by_category.items()
        for tool_name in tool_list
        if category != selected_category
    ]
    
    # Get a random sample of 20 other tools
    num_random_tools = 10 # <----------------------------- number of random added tools (20)
    if len(other_tools) > num_random_tools:
        random_sample = random.sample(other_tools, num_random_tools)
        print(f"Adding a random sample of {len(random_sample)} tools from other categories.")
    else:
        random_sample = other_tools  # Take all if less than 20 are available
        print(f"Adding all {len(random_sample)} available tools from other categories (fewer than {num_random_tools}).")

    # Combine the lists of tool names and remove duplicates
    final_tool_names = list(set(tools_for_category + random_sample))

    # Map tool names (strings) to actual function objects
    tool_functions = []
    for tool_name in final_tool_names:
        # Assumes 'from all_smol_agent_tools import *' has put the functions in the global scope
        tool_func = globals().get(tool_name)
        if tool_func and callable(tool_func):
             tool_functions.append(tool_func)
        else:
            print(f"  -> WARNING: Tool function '{tool_name}' not found and will be skipped.")
    
    # --- Load Tasks ---
    try:
        with open(TASKS_FILE, 'r') as f:
            all_task_records = json.load(f)
    except FileNotFoundError:
        print(f"ERROR: Tasks file not found at {TASKS_FILE}")
        exit()
        
    tasks_to_run = [
        record 
        for record in all_task_records 
        if record.get("category") == selected_category
    ]
        
    if not tasks_to_run:
        print(f"ERROR: No tasks found for category '{selected_category}' in {TASKS_FILE}")
        exit()
        
    print(f"Found {len(tasks_to_run)} tasks for this category.")
    
    # --- Main Processing Loop ---
    for i, task_record in enumerate(tasks_to_run):
        
        # 1. Extract the id and instruction from the record
        task_id = task_record.get("my_id", f"unknownID_{i}")#"id" # Fallback in case id is missing
        task_prompt = task_record.get("instruction", "")

        if not task_prompt:
            print(f"  -> WARNING: Skipping record with ID {task_id} due to missing 'instruction'.")
            continue

        print(f"\n--- Processing Task {i+1}/{len(tasks_to_run)} (ID: {task_id}) ---")
        
        timestamp = datetime.now().strftime("%d-%m_%H-%M-%S")
        unique_id = f"{selected_category.replace(' ', '_')}_ID{task_id}_{model_id_short}_{timestamp}"
        
        # 2. Run the agent
        agent_output_log = run_my_agent(task_prompt, tool_functions)
        
        # 3. Save the agent's full log output
        agent_output_filename = os.path.join(OUTPUT_DIR, f"{unique_id}_agent_out.dill")
        with open(agent_output_filename, "wb") as f:
            dill.dump(agent_output_log, f)
        print(f"  -> Agent log saved to: {agent_output_filename}")

        # 4. Preprocess the models memory to be used as strings by inseq
        agent_input_string, agent_output_string = prepare_for_inseq(agent_output_log, tokenizer)
        
        # 5. Run the Inseq analysis
        inseq_output_object = run_inseq_analysis(agent_input_string, agent_output_string)
        
        # 5. Save the complex Inseq object using dill
        inseq_output_filename = os.path.join(OUTPUT_DIR, f"{unique_id}_inseq_out.dill")
        with open(inseq_output_filename, "wb") as f:
            dill.dump(inseq_output_object, f)
        print(f"  -> Inseq object saved to: {inseq_output_filename}")

    print("\n All tasks for the category completed successfully!")