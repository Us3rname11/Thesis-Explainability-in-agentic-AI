{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Dataset Analytics Results ---------\n",
      "\n",
      "[1] Found 40 unique tasks:\n",
      "    - apply_for_job\n",
      "    - apply_for_passport\n",
      "    - attend_meeting_online\n",
      "    - auto_driving_to_destination\n",
      "    - auto_housework_by_robot\n",
      "    - book_car\n",
      "    - book_flight\n",
      "    - book_hotel\n",
      "    - book_restaurant\n",
      "    - borrow_book_online\n",
      "    - buy_insurance\n",
      "    - consult_lawyer_online\n",
      "    - daily_bill_payment\n",
      "    - deliver_package\n",
      "    - do_tax_return\n",
      "    - enroll_in_course\n",
      "    - get_news_for_topic\n",
      "    - get_weather\n",
      "    - make_video_call\n",
      "    - make_voice_call\n",
      "    - online_banking\n",
      "    - online_shopping\n",
      "    - order_food_delivery\n",
      "    - order_taxi\n",
      "    - organize_meeting_online\n",
      "    - pay_for_credit_card\n",
      "    - play_movie_by_title\n",
      "    - play_music_by_title\n",
      "    - print_document\n",
      "    - recording_audio\n",
      "    - search_by_engine\n",
      "    - see_doctor_online\n",
      "    - sell_item_online\n",
      "    - send_email\n",
      "    - send_sms\n",
      "    - set_alarm\n",
      "    - share_by_social_network\n",
      "    - software_management\n",
      "    - stock_operation\n",
      "    - take_note\n",
      "\n",
      "[2] Records per unique task:\n",
      "    - apply_for_job: 3 records\n",
      "    - apply_for_passport: 2 records\n",
      "    - attend_meeting_online: 3 records\n",
      "    - auto_driving_to_destination: 3 records\n",
      "    - auto_housework_by_robot: 3 records\n",
      "    - book_car: 2 records\n",
      "    - book_flight: 2 records\n",
      "    - book_hotel: 2 records\n",
      "    - book_restaurant: 3 records\n",
      "    - borrow_book_online: 3 records\n",
      "    - buy_insurance: 2 records\n",
      "    - consult_lawyer_online: 2 records\n",
      "    - daily_bill_payment: 3 records\n",
      "    - deliver_package: 2 records\n",
      "    - do_tax_return: 3 records\n",
      "    - enroll_in_course: 3 records\n",
      "    - get_news_for_topic: 3 records\n",
      "    - get_weather: 3 records\n",
      "    - make_video_call: 3 records\n",
      "    - make_voice_call: 2 records\n",
      "    - online_banking: 2 records\n",
      "    - online_shopping: 3 records\n",
      "    - order_food_delivery: 3 records\n",
      "    - order_taxi: 2 records\n",
      "    - organize_meeting_online: 2 records\n",
      "    - pay_for_credit_card: 2 records\n",
      "    - play_movie_by_title: 3 records\n",
      "    - play_music_by_title: 3 records\n",
      "    - print_document: 3 records\n",
      "    - recording_audio: 2 records\n",
      "    - search_by_engine: 2 records\n",
      "    - see_doctor_online: 2 records\n",
      "    - sell_item_online: 3 records\n",
      "    - send_email: 3 records\n",
      "    - send_sms: 3 records\n",
      "    - set_alarm: 2 records\n",
      "    - share_by_social_network: 3 records\n",
      "    - software_management: 2 records\n",
      "    - stock_operation: 3 records\n",
      "    - take_note: 2 records\n",
      "\n",
      "[3] Unique tasks per category:\n",
      "    - business_and_prod: 11 unique tasks\n",
      "    - data: 4 unique tasks\n",
      "    - entertain_and_media: 10 unique tasks\n",
      "    - finance: 6 unique tasks\n",
      "    - travel_and_transp: 9 unique tasks\n",
      "\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "def analyze_data(filepath):\n",
    "    \"\"\"\n",
    "    Analyzes a JSON dataset to count tasks and categories.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): The path to the JSON dataset file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{filepath}' was not found.\")\n",
    "        return\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: The file '{filepath}' is not a valid JSON file.\")\n",
    "        return\n",
    "\n",
    "    # --- Data structures for analytics ---\n",
    "    # To store all unique task strings\n",
    "    unique_tasks = set()\n",
    "    # To count occurrences of each task across all records\n",
    "    task_record_counts = defaultdict(int)\n",
    "    # To map categories to the unique tasks they contain\n",
    "    category_to_tasks = defaultdict(set)\n",
    "\n",
    "    # --- Process each record in the dataset ---\n",
    "    for record in data:\n",
    "        category = record.get('category', 'Uncategorized')\n",
    "        nodes = record.get('sampled_nodes', [])\n",
    "\n",
    "        if not isinstance(nodes, list):\n",
    "            continue # Skip if 'sampled_nodes' isn't a list\n",
    "\n",
    "        for node in nodes:\n",
    "            task = node.get('task')\n",
    "            if task:\n",
    "                # Add the task to our analytics collections\n",
    "                unique_tasks.add(task)\n",
    "                task_record_counts[task] += 1\n",
    "                category_to_tasks[category].add(task)\n",
    "\n",
    "    # --- Display the results ---\n",
    "    print(\"--------- Dataset Analytics Results ---------\")\n",
    "\n",
    "    # 1. Count and list all unique task strings\n",
    "    print(f\"\\n[1] Found {len(unique_tasks)} unique tasks:\")\n",
    "    for task in sorted(list(unique_tasks)):\n",
    "        print(f\"    - {task}\")\n",
    "\n",
    "    # 2. Count records per unique task string\n",
    "    print(\"\\n[2] Records per unique task:\")\n",
    "    for task, count in sorted(task_record_counts.items()):\n",
    "        print(f\"    - {task}: {count} records\")\n",
    "\n",
    "    # 3. Count unique tasks per category\n",
    "    print(\"\\n[3] Unique tasks per category:\")\n",
    "    for category, tasks in sorted(category_to_tasks.items()):\n",
    "        print(f\"    - {category}: {len(tasks)} unique tasks\")\n",
    "\n",
    "    print(\"\\n-------------------------------------------\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # The name of the dataset file you want to analyze.\n",
    "    # Make sure this file is in the same directory as the script.\n",
    "    DATASET_FILE = \"/Users/val/MA/Code/main_folder/data/filtered_dataset.json\"\n",
    "    analyze_data(DATASET_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Dataset Analytics Results ---------\n",
      "\n",
      "[*] Total records analyzed: 256\n",
      "\n",
      "[1] Found 100 unique tasks:\n",
      "    - add_item_to_trip_itinerary\n",
      "    - analyze_monthly_spending\n",
      "    - apply_for_job\n",
      "    - apply_for_passport\n",
      "    - attend_meeting_online\n",
      "    - auto_driving_to_destination\n",
      "    - auto_housework_by_robot\n",
      "    - automate_loan_payment\n",
      "    - book_car\n",
      "    - book_flight\n",
      "    - book_hotel\n",
      "    - book_movie_tickets\n",
      "    - book_restaurant\n",
      "    - book_train_ticket\n",
      "    - borrow_book_online\n",
      "    - buy_insurance\n",
      "    - check_credit_score\n",
      "    - check_flight_status\n",
      "    - clean_dataset\n",
      "    - compare_rental_car_prices\n",
      "    - compare_two_documents\n",
      "    - compress_file\n",
      "    - consult_lawyer_online\n",
      "    - convert_currency\n",
      "    - convert_file_format\n",
      "    - create_qr_code\n",
      "    - create_savings_goal\n",
      "    - create_spreadsheet_from_data\n",
      "    - create_team_poll\n",
      "    - daily_bill_payment\n",
      "    - deliver_package\n",
      "    - do_tax_return\n",
      "    - enroll_in_course\n",
      "    - extract_data_from_website\n",
      "    - extract_tabular_data_from_pdf\n",
      "    - extract_text_from_image\n",
      "    - find_airport_lounge_access\n",
      "    - find_local_events_and_concerts\n",
      "    - find_nearby_atm\n",
      "    - find_nearby_electric_vehicle_charger\n",
      "    - find_podcast_on_topic\n",
      "    - find_travel_visa_requirements\n",
      "    - generate_chart_from_data\n",
      "    - generate_meeting_summary\n",
      "    - get_crypto_price\n",
      "    - get_data_from_public_api\n",
      "    - get_latest_sports_scores\n",
      "    - get_lyrics_for_song\n",
      "    - get_news_for_topic\n",
      "    - get_random_trivia_question\n",
      "    - get_real_time_traffic_update\n",
      "    - get_stock_quote\n",
      "    - get_tv_show_recommendations\n",
      "    - get_weather\n",
      "    - identify_song_playing\n",
      "    - identify_tax_deductible_expenses\n",
      "    - initiate_code_repository\n",
      "    - log_work_hours\n",
      "    - make_video_call\n",
      "    - make_voice_call\n",
      "    - manage_crm_contact\n",
      "    - merge_documents\n",
      "    - online_banking\n",
      "    - online_shopping\n",
      "    - order_food_delivery\n",
      "    - order_taxi\n",
      "    - organize_meeting_online\n",
      "    - pay_for_credit_card\n",
      "    - perform_sentiment_analysis_on_text\n",
      "    - plan_public_transport_route\n",
      "    - play_movie_by_title\n",
      "    - play_music_by_title\n",
      "    - print_document\n",
      "    - query_dataset_with_natural_language\n",
      "    - query_internal_knowledge_base\n",
      "    - read_aloud_news_headlines\n",
      "    - recording_audio\n",
      "    - redact_sensitive_information\n",
      "    - schedule_follow_up_communication\n",
      "    - search_by_engine\n",
      "    - search_transaction_history\n",
      "    - see_doctor_online\n",
      "    - sell_item_online\n",
      "    - send_email\n",
      "    - send_money_to_contact\n",
      "    - send_sms\n",
      "    - set_alarm\n",
      "    - set_budget_for_category\n",
      "    - share_by_social_network\n",
      "    - software_management\n",
      "    - split_bill_with_friends\n",
      "    - start_multiplayer_game\n",
      "    - stock_operation\n",
      "    - summarize_article_from_url\n",
      "    - take_note\n",
      "    - track_investment_portfolio\n",
      "    - track_luggage\n",
      "    - track_project_progress\n",
      "    - transcribe_meeting_audio\n",
      "    - translate_sign_or_menu_with_camera\n",
      "\n",
      "[2] Records per unique task:\n",
      "    - add_item_to_trip_itinerary: 3 records\n",
      "    - analyze_monthly_spending: 3 records\n",
      "    - apply_for_job: 3 records\n",
      "    - apply_for_passport: 2 records\n",
      "    - attend_meeting_online: 3 records\n",
      "    - auto_driving_to_destination: 3 records\n",
      "    - auto_housework_by_robot: 3 records\n",
      "    - automate_loan_payment: 2 records\n",
      "    - book_car: 2 records\n",
      "    - book_flight: 2 records\n",
      "    - book_hotel: 2 records\n",
      "    - book_movie_tickets: 3 records\n",
      "    - book_restaurant: 3 records\n",
      "    - book_train_ticket: 2 records\n",
      "    - borrow_book_online: 3 records\n",
      "    - buy_insurance: 2 records\n",
      "    - check_credit_score: 2 records\n",
      "    - check_flight_status: 3 records\n",
      "    - clean_dataset: 3 records\n",
      "    - compare_rental_car_prices: 2 records\n",
      "    - compare_two_documents: 2 records\n",
      "    - compress_file: 2 records\n",
      "    - consult_lawyer_online: 2 records\n",
      "    - convert_currency: 4 records\n",
      "    - convert_file_format: 3 records\n",
      "    - create_qr_code: 2 records\n",
      "    - create_savings_goal: 2 records\n",
      "    - create_spreadsheet_from_data: 3 records\n",
      "    - create_team_poll: 3 records\n",
      "    - daily_bill_payment: 3 records\n",
      "    - deliver_package: 2 records\n",
      "    - do_tax_return: 3 records\n",
      "    - enroll_in_course: 3 records\n",
      "    - extract_data_from_website: 2 records\n",
      "    - extract_tabular_data_from_pdf: 3 records\n",
      "    - extract_text_from_image: 3 records\n",
      "    - find_airport_lounge_access: 2 records\n",
      "    - find_local_events_and_concerts: 2 records\n",
      "    - find_nearby_atm: 2 records\n",
      "    - find_nearby_electric_vehicle_charger: 3 records\n",
      "    - find_podcast_on_topic: 3 records\n",
      "    - find_travel_visa_requirements: 3 records\n",
      "    - generate_chart_from_data: 3 records\n",
      "    - generate_meeting_summary: 3 records\n",
      "    - get_crypto_price: 4 records\n",
      "    - get_data_from_public_api: 2 records\n",
      "    - get_latest_sports_scores: 3 records\n",
      "    - get_lyrics_for_song: 2 records\n",
      "    - get_news_for_topic: 3 records\n",
      "    - get_random_trivia_question: 2 records\n",
      "    - get_real_time_traffic_update: 3 records\n",
      "    - get_stock_quote: 3 records\n",
      "    - get_tv_show_recommendations: 3 records\n",
      "    - get_weather: 3 records\n",
      "    - identify_song_playing: 2 records\n",
      "    - identify_tax_deductible_expenses: 2 records\n",
      "    - initiate_code_repository: 2 records\n",
      "    - log_work_hours: 2 records\n",
      "    - make_video_call: 3 records\n",
      "    - make_voice_call: 2 records\n",
      "    - manage_crm_contact: 3 records\n",
      "    - merge_documents: 2 records\n",
      "    - online_banking: 2 records\n",
      "    - online_shopping: 3 records\n",
      "    - order_food_delivery: 3 records\n",
      "    - order_taxi: 2 records\n",
      "    - organize_meeting_online: 2 records\n",
      "    - pay_for_credit_card: 2 records\n",
      "    - perform_sentiment_analysis_on_text: 2 records\n",
      "    - plan_public_transport_route: 3 records\n",
      "    - play_movie_by_title: 3 records\n",
      "    - play_music_by_title: 3 records\n",
      "    - print_document: 3 records\n",
      "    - query_dataset_with_natural_language: 3 records\n",
      "    - query_internal_knowledge_base: 2 records\n",
      "    - read_aloud_news_headlines: 2 records\n",
      "    - recording_audio: 2 records\n",
      "    - redact_sensitive_information: 2 records\n",
      "    - schedule_follow_up_communication: 2 records\n",
      "    - search_by_engine: 2 records\n",
      "    - search_transaction_history: 3 records\n",
      "    - see_doctor_online: 2 records\n",
      "    - sell_item_online: 3 records\n",
      "    - send_email: 3 records\n",
      "    - send_money_to_contact: 3 records\n",
      "    - send_sms: 3 records\n",
      "    - set_alarm: 2 records\n",
      "    - set_budget_for_category: 3 records\n",
      "    - share_by_social_network: 3 records\n",
      "    - software_management: 2 records\n",
      "    - split_bill_with_friends: 2 records\n",
      "    - start_multiplayer_game: 3 records\n",
      "    - stock_operation: 3 records\n",
      "    - summarize_article_from_url: 3 records\n",
      "    - take_note: 2 records\n",
      "    - track_investment_portfolio: 3 records\n",
      "    - track_luggage: 2 records\n",
      "    - track_project_progress: 3 records\n",
      "    - transcribe_meeting_audio: 3 records\n",
      "    - translate_sign_or_menu_with_camera: 2 records\n",
      "\n",
      "[3] Unique tasks per category:\n",
      "    - business_and_productivity: 20 unique tasks\n",
      "    - business_and_productivityuctivity: 1 unique tasks\n",
      "    - data: 20 unique tasks\n",
      "    - entertainment_and_media: 20 unique tasks\n",
      "    - finance: 20 unique tasks\n",
      "    - travel_and_transportation: 20 unique tasks\n",
      "\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "def analyze_data(filepath):\n",
    "    \"\"\"\n",
    "    Analyzes a JSON dataset to count tasks and categories.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): The path to the JSON dataset file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{filepath}' was not found.\")\n",
    "        return\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: The file '{filepath}' is not a valid JSON file.\")\n",
    "        return\n",
    "\n",
    "    # --- Data structures for analytics ---\n",
    "    # To store all unique task strings\n",
    "    unique_tasks = set()\n",
    "    # To count occurrences of each task across all records\n",
    "    task_record_counts = defaultdict(int)\n",
    "    # To map categories to the unique tasks they contain\n",
    "    category_to_tasks = defaultdict(set)\n",
    "\n",
    "    # --- Process each record in the dataset ---\n",
    "    for record in data:\n",
    "        category = record.get('category', 'Uncategorized')\n",
    "        nodes = record.get('sampled_nodes', [])\n",
    "\n",
    "        if not isinstance(nodes, list):\n",
    "            continue # Skip if 'sampled_nodes' isn't a list\n",
    "\n",
    "        for node in nodes:\n",
    "            task = node.get('task')\n",
    "            if task:\n",
    "                # Add the task to our analytics collections\n",
    "                unique_tasks.add(task)\n",
    "                task_record_counts[task] += 1\n",
    "                category_to_tasks[category].add(task)\n",
    "\n",
    "    # --- Display the results ---\n",
    "    print(\"--------- Dataset Analytics Results ---------\")\n",
    "\n",
    "    print(f\"\\n[*] Total records analyzed: {len(data)}\")\n",
    "\n",
    "    # 1. Count and list all unique task strings\n",
    "    print(f\"\\n[1] Found {len(unique_tasks)} unique tasks:\")\n",
    "    for task in sorted(list(unique_tasks)):\n",
    "        print(f\"    - {task}\")\n",
    "\n",
    "    # 2. Count records per unique task string\n",
    "    print(\"\\n[2] Records per unique task:\")\n",
    "    for task, count in sorted(task_record_counts.items()):\n",
    "        print(f\"    - {task}: {count} records\")\n",
    "\n",
    "    # 3. Count unique tasks per category\n",
    "    print(\"\\n[3] Unique tasks per category:\")\n",
    "    for category, tasks in sorted(category_to_tasks.items()):\n",
    "        print(f\"    - {category}: {len(tasks)} unique tasks\")\n",
    "\n",
    "    print(\"\\n-------------------------------------------\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # The name of the dataset file you want to analyze.\n",
    "    # Make sure this file is in the same directory as the script.\n",
    "    DATASET_FILE = \"/Users/val/MA/Code/main_folder/data/dataset_combined.json\"\n",
    "    analyze_data(DATASET_FILE)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10 (v3.12.10:0cc81280367, Apr  8 2025, 08:46:59) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6bfb36e1809ebaabb37e5aa29ecba9279008a69c1743045940bd5d510f792dfd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
